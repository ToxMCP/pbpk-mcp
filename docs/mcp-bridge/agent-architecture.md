# Conversational Agent Architecture (LangChain/LangGraph)

## 1. Overview

This document captures the architecture for the confirm-before-execute
conversational agent that will orchestrate the MCP Bridge. The agent is
implemented with LangChain and LangGraph to provide explicit control over
planning, tool selection, human confirmation, and execution while preserving a
verifiable audit trail.

### Objectives

- Translate high-level user goals into a safe sequence of MCP tool invocations.
- Enforce clarification and human confirmation before mutating or
  compute-intensive operations (`set_parameter_value`, `run_simulation`,
  `load_simulation`).
- Provide deterministic state management, retry/backoff behaviour, and an
  inspectable conversation history that doubles as a lab notebook entry.

## 2. Framework Selection Rationale

| Requirement | Rationale for LangChain/LangGraph |
|-------------|-----------------------------------|
| **Explicit state** | LangGraph exposes the agent as a state machine driven by a `StateGraph`, making the conversation history, simulation context, and pending plans first-class state. |
| **Human-in-the-loop** | `interrupt()` support allows the graph to pause on critical actions and resume once the user approves. |
| **Custom tool orchestration** | LangChain tool wrappers let us surface existing MCP REST endpoints with JSON schemas that LangGraph can reason about. |
| **Retry/backoff** | Graph edges can branch into error recovery nodes where transient failures trigger exponential backoff or re-planning. |
| **Open-source and extensible** | Aligns with the project’s open-source ethos and avoids vendor lock-in associated with managed assistant APIs. |

## 3. AgentState Definition

All nodes in the graph share a typed `AgentState` object. The schema (implemented
as a `TypedDict` or Pydantic model) contains:

| Field | Type | Description |
|-------|------|-------------|
| `messages` | `List[BaseMessage]` | Complete conversation history. Reducer: `operator.add`. |
| `simulation_context` | `Optional[dict]` | Metadata about the active simulation (e.g., `simulationId`, `modelPath`). Populated after successful `load_simulation`. |
| `pending_tool_call` | `Optional[dict]` | Structured payload describing the next critical action awaiting user approval (tool name, arguments, justification, summary text). |
| `user_feedback` | `Optional[str]` | Normalised response from the user when the graph resumes after an interrupt. |
| `plan` | `Optional[dict]` | Latest plan or next step generated by the planner node (tool name, arguments, reasoning). |
| `intermediate_steps` | `List[dict]` | Log of executed tool calls, results, and errors for auditability. |
| `awaiting_confirmation` | `bool` | Flag set by the confirmation node signalling that the host must pause and gather explicit user approval. |
| `confirmation_prompt` | `Optional[str]` | Render-ready summary describing the pending critical action. |
| `retry_counts` | `Dict[str, int]` | Per-tool retry counters used by the execution node to enforce backoff. |

Persistence requirement: the compiled graph must enable a checkpointer (initially
`InMemorySaver`, with a path to upgrade). Without a checkpointer the
human-in-the-loop interrupt mechanism cannot resume execution.

## 4. Node Inventory and Responsibilities

| Node | Responsibilities |
|------|------------------|
| **Planner_Node** | Call LLM planner prompt to produce/update plan; record plan; append planner message. |
| **Tool_Selection_Node** | Inspect plan, choose next tool, populate `pending_tool_call` (including templated summary for confirmation). |
| **Confirmation_Gate_Node** | Invoke `interrupt(state["pending_tool_call"])`, pausing the graph and surfacing the action to the application layer for user approval. |
| **Tool_Execution_Node** | Execute MCP tool wrappers; on success append to `intermediate_steps`; update `messages`; on error route to recovery logic. |
| **Response_Synthesis_Node** | Summarise outcomes back to user via LLM; clear transient state such as `plan` and `pending_tool_call`. |
| **Error_Recovery_Node** *(implicit)* | Handle adapter/HTTP failures via retry/backoff, or escalate to planner for re-thinking. |

## 5. Confirmation Flow

1. Planner selects a critical action and sets `pending_tool_call` with tool name,
   arguments, and justification.
2. Selection node routes to confirmation if the tool is in
   `CRITICAL_TOOLS = {"set_parameter_value", "run_simulation", "load_simulation"}`.
3. Confirmation node pauses via `interrupt()` and the host renders a structured
   message, e.g.:

```
Tool: set_parameter_value
Simulation ID: {simulation_id}
Parameter Path: {parameter_path}
New Value: {value} {unit}
Approve? (yes/no)
```

4. On resume, `user_feedback` is normalised. Approval routes to execution; denial
   clears `pending_tool_call` and routes back to the planner to propose an
   alternative plan or ask for further clarification.

## 6. Safety Guardrails

- **Tool whitelisting**: only registered MCP tool wrappers can be called; planner
  prompt enumerates allowed tools.
- **Parameter validation**: wrappers perform local validation prior to invoking
  the REST API (units, numeric ranges, required fields).
- **Retry/backoff**: transient adapter failures (HTTP 502/503/timeout) trigger
  exponential backoff with caps; persistent failures surface to the planner.
- **Conversation record**: all confirmation prompts and user approvals/denials are
  appended to `messages`, providing a verifiable audit trail.

## 7. Prompt Strategy

- **System prompt**: defines cautious PK assistant persona, lists tools, mandates
  clarification of ambiguous instructions, and enforces the confirm-before-execute
  policy.
- **Planner prompt**: instructs the LLM to produce step-by-step plans referencing
  only available tools and to flag whether the next action is critical.
- **Executor prompt**: synthesises responses after execution, echoing actions
  taken and results.
- **Confirmation templates**: deterministic strings for each critical tool so the
  user always sees clear, consistent summaries.

## 8. Implementation Guidance

1. **Scaffolding**: instantiate `StateGraph(AgentState)`, register nodes, and
   compile with `InMemorySaver()` to enable interrupts.
2. **Conditional edges**: implement `route_after_selection` and
   `route_after_confirmation` helpers to dictate transitions and honour the
   safety protocol.
3. **Application loop**: the host (FastAPI/CLI) must invoke the graph with a
   persistent `thread_id`, detect `state["awaiting_confirmation"]` or
   `{"__interrupt__": ...}` responses, present `confirmation_prompt` verbatim to
   the user, record their answer, and resume with the next invocation setting
   `state["user_feedback"]` (and optionally a transcript message) before calling
   `graph.invoke` again. Hosts consuming long-running jobs should subscribe to
   `/jobs/{job_id}/events` (server‑sent events) to stream progress updates back to
   the user while the graph awaits results.
4. **Testing**: golden dialogues in
   `tests/integration/test_agent_dialogues.py` cover happy path (load -> run),
   ambiguous input resolution, and rejection flow, ensuring safety rails remain
   intact as prompts and tooling evolve.

## 9. Open Questions & Future Work

- Persist the checkpointer to Redis/Postgres for durability across restarts.
- Extend `AgentState` with richer plan metadata to support multi-step batch
  operations (sensitivity analysis, population runs).
- Integrate LangSmith tracing for production monitoring of the agent graph.
