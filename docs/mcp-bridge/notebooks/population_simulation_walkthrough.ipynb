{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Population Simulation Quickstart\n",
    "\n",
    "This notebook demonstrates how to submit a cohort simulation via the MCP bridge,\n",
    "poll for completion, and retrieve claim-check artefacts. Configure the\n",
    "connection details in the first cell before executing the workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configure API access\n",
    "\n",
    "Set `MCP_BASE_URL` and `MCP_TOKEN` in your environment (for example by using\n",
    "`direnv` or a `.env` file). The confirmation header is required for critical\n",
    "tools such as `run_population_simulation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import requests\n",
    "\n",
    "BASE_URL = os.environ.get(\"MCP_BASE_URL\", \"http://localhost:8000\")\n",
    "TOKEN = os.environ[\"MCP_TOKEN\"]\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {TOKEN}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"X-MCP-Confirm\": \"true\",\n",
    "}\n",
    "\n",
    "def _post(path: str, payload: dict) -> requests.Response:\n",
    "    url = f\"{BASE_URL}{path}\"\n",
    "    response = requests.post(url, headers=HEADERS, data=json.dumps(payload), timeout=30)\n",
    "    response.raise_for_status()\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load a simulation baseline\n",
    "\n",
    "Provide the path to a `.pkml` model accessible to the bridge. The response\n",
    "confirms the simulation identifier that subsequent calls must reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Path(\"tests/fixtures/demo.pkml\").as_posix()\n",
    "simulation_id = \"population-demo\"\n",
    "\n",
    "load_payload = {\"filePath\": model_path, \"simulationId\": simulation_id}\n",
    "load_response = _post(\"/load_simulation\", load_payload)\n",
    "load_response.json()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Submit a population simulation job\n",
    "\n",
    "Here we request a 200-subject Latin Hypercube run with mean and p95 aggregates.\n",
    "The API immediately returns a job identifier that we can poll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_payload = {\n",
    "    \"modelPath\": model_path,\n",
    "    \"simulationId\": simulation_id,\n",
    "    \"cohort\": {\"size\": 200, \"sampling\": \"latinHypercube\", \"seed\": 42},\n",
    "    \"outputs\": {\"aggregates\": [\"mean\", \"p95\"]},\n",
    "    \"metadata\": {\"notebook\": \"population_quickstart\"},\n",
    "}\n",
    "population_response = _post(\"/run_population_simulation\", population_payload)\n",
    "job_id = population_response.json()[\"jobId\"]\n",
    "job_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Poll for completion\n",
    "\n",
    "Poll `get_job_status` until the job leaves the `queued`/`running` states. The\n",
    "result handle contains a `resultsId` that can be exchanged for aggregates and\n",
    "chunk metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_payload = {\"jobId\": job_id}\n",
    "while True:\n",
    "    status_response = _post(\"/get_job_status\", status_payload)\n",
    "    job = status_response.json()[\"job\"]\n",
    "    print(job[\"status\"], job.get(\"queueWaitSeconds\"))\n",
    "    if job[\"status\"].lower() not in {\"queued\", \"running\"}:\n",
    "        results_handle = job.get(\"resultHandle\", {})\n",
    "        break\n",
    "    time.sleep(1.0)\n",
    "\n",
    "results_handle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fetch aggregates and chunk metadata\n",
    "\n",
    "Population results include both summary aggregates and chunk references.\n",
    "Streaming large chunk payloads is optionalâ€”only download the pieces you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_id = results_handle[\"resultsId\"]\n",
    "results_payload = {\"resultsId\": results_id}\n",
    "results_response = _post(\"/get_population_results\", results_payload)\n",
    "results_data = results_response.json()\n",
    "\n",
    "aggregates = results_data[\"aggregates\"]\n",
    "first_chunk = results_data[\"chunks\"][0]\n",
    "\n",
    "aggregates, first_chunk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. (Optional) Download a chunk\n",
    "\n",
    "Chunks are retrieved via an authenticated `GET` request. Save them to disk for\n",
    "post-processing in pandas or visualization tooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_id = first_chunk[\"chunkId\"]\n",
    "chunk_url = f\"{BASE_URL}/population_results/{results_id}/chunks/{chunk_id}\"\n",
    "chunk_response = requests.get(chunk_url, headers={\"Authorization\": f\"Bearer {TOKEN}\"}, timeout=30)\n",
    "chunk_response.raise_for_status()\n",
    "\n",
    "output_path = Path(\"population_chunk.json\")\n",
    "output_path.write_bytes(chunk_response.content)\n",
    "output_path\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
